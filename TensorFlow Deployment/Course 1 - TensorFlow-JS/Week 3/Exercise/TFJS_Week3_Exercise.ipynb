{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TFJS_Week3_Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrew-veriga/dlaicourse/blob/master/TensorFlow%20Deployment/Course%201%20-%20TensorFlow-JS/Week%203/Exercise/TFJS_Week3_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Преобразование модели Keras в формат JSON\n",
        "\n",
        "На предыдущем уроке вы узнали, как использовать CNN, чтобы сделать распознавание рукописных цифр более эффективным. В этом уроке вы перейдете на следующий уровень, распознавая реальные изображения кошек и собак, чтобы классифицировать входящее изображение как одно или другое. В частности, распознавание рукописного ввода сделало вашу жизнь немного проще, поскольку все изображения были одного размера и формы, и все они были монохромными. Реальные изображения не такие - они разных форм, соотношений сторон и т.д., И, кроме того, обычно они цветные.\n",
        "\n",
        "Как часть задачи вам необходимо обработать данные - изменить их размер, чтобы они были одинаковыми по форме.\n",
        "\n",
        "Вы выполните следующие действия:\n",
        "\n",
        "1. Изучите пример данных о кошках и собаках.\n",
        "2. Построете и обучите нейронную сеть, их различающую.\n",
        "3. Оцените точность обучения и проверки.\n",
        "4. Сохраните обученную модель как файл Keras HDF5.\n",
        "5. При помощи конвертера tensorflow.js, преобразуете сохраненную модель Keras в формат JSON.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V4Y3xdzQSSf"
      },
      "source": [
        "# Импорт ресурсов\n",
        "\n",
        "Чтобы использовать преобразователь tensorflow.js, нам необходимо установить `tensorflowjs`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd66XRfdQSSf"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeIhBRZtQSSj"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print('\\u2022 Using TensorFlow Version:', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY6KJV6z6l7_"
      },
      "source": [
        "## Изучите примеры данных\n",
        "\n",
        "Начнем с загрузки данных из нашего примера, архива .zip с изображениями кошек и собак в формате JPG и его распаковки в локальный каталог `/ tmp`.\n",
        "\n",
        "**Примечание:**  2000 изображений, используемых в этом упражнении, взяты из [набора данных «Собаки против кошек»] (https://www.kaggle.com/c/dogs-vs-cats/data), доступного на Kaggle, который содержит 25 000 изображений. Здесь мы используем подмножество полного набора данных, чтобы сократить время обучения в образовательных целях."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXZT2UsyIVe_"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "  -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9brUxyTpYZHy"
      },
      "source": [
        "Следующий код Python будет использовать библиотеку OS, предоставляющую  доступ к файловой системе, и библиотеку zipfile, позволяющую распаковать данные."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLy3pthUS0D2"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-qUPyfO7Qr8"
      },
      "source": [
        "Содержимое .zip извлекается в базовый каталог `/tmp/cats_and_dogs_filtered`, который содержит подкаталоги` train` и `validation` для наборов данных обучения и проверки, каждый из которых, в свою очередь, содержит подкаталоги \"cats\" и \"dogs\".\n",
        "\n",
        "В этом примере следует вспомнить: мы не маркируем изображения явно как кошек или собак. В примере с рукописным вводом ранее мы пометили «это 1», «это 7» и т.д. Здесь они автоматически размечиваются по имени своих подкаталогов. ImageGenerator размечает изображения соответствующим образом, сокращая этап кодирования.\n",
        "\n",
        "Определим эти каталоги:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZKVtE0dSfk"
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat/dog pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat/dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuBYtA_Zd8_T"
      },
      "source": [
        "\n",
        "Теперь давайте посмотрим, как выглядят имена файлов в каталогах `cats` и` dogs`, `train` (соглашения об именах файлов в каталоге` validation` одинаковы):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PIP1rkmeAYS"
      },
      "source": [
        "train_cat_fnames = os.listdir( train_cats_dir )\n",
        "train_dog_fnames = os.listdir( train_dogs_dir )\n",
        "\n",
        "print(train_cat_fnames[:10])\n",
        "print(train_dog_fnames[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlqN5KbafhLI"
      },
      "source": [
        "Узнаем общее количество изображений кошек и собак в каталогах `train` и `validation`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4XHh2xSfgie"
      },
      "source": [
        "print('total training cat images :', len(os.listdir(      train_cats_dir ) ))\n",
        "print('total training dog images :', len(os.listdir(      train_dogs_dir ) ))\n",
        "\n",
        "print('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\n",
        "print('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3WZABE9eX-8"
      },
      "source": [
        "И для кошек, и для собак у нас есть 1000 обучающих изображений и 500 проверочных изображений.\n",
        "\n",
        "Теперь выведем несколько изображений, чтобы лучше понять, как выглядят наборы данных о кошках и собаках. Сначала мы настраиваем параметры `matplotlib`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2_Q0-_5UAv-"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 0 # Index for iterating over images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvHzGCxXkqp"
      },
      "source": [
        "Отобразим серию из 8 изображений кошек и 8 собак. Вы можете повторно запускать ячейку, чтобы каждый раз видеть новую партию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpr8GxjOU8in"
      },
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=8\n",
        "\n",
        "next_cat_pix = [os.path.join(train_cats_dir, fname) \n",
        "                for fname in train_cat_fnames[ pic_index-8:pic_index] \n",
        "               ]\n",
        "\n",
        "next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
        "                for fname in train_dog_fnames[ pic_index-8:pic_index]\n",
        "               ]\n",
        "\n",
        "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
        "    # Set up subplot; subplot indices start at 1\n",
        "    sp = plt.subplot(nrows, ncols, i + 1)\n",
        "    sp.axis('Off') # Don't show axes (or gridlines)\n",
        "    \n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQhDdYPEZvJt"
      },
      "source": [
        "\n",
        "Существенное отличие от предыдущего урока в том, что эти изображения бывают разных форм и размеров. Когда вы делали пример распознавания рукописного ввода, вам приходилось работать с изображениями в оттенках серого 28x28. Здесь они бывают цветными и разные по форме и размерам. Перед обучением нейронной сети с ними вам необходимо настроить изображения. Вы увидите это в следующем разделе.\n",
        "\n",
        "Теперь, когда у вас есть представление о том, как выглядят ваши данные, следующим шагом будет создание модели, которая будет обучена распознавать кошек или собак по этим изображениям."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oqBkNBJmtUv"
      },
      "source": [
        "## Создание небольшой модели с нуля для достижения точности ~ 72%\n",
        "\n",
        "В предыдущем разделе вы видели, что изображения разных форм и размеров. Чтобы обучить нейронную сеть обрабатывать их, нужно сделать их одного размера. Здесь мы выбрали размер 150x150, и вскоре вы увидите код, который предварительно обрабатывает изображения до этой формы.\n",
        "\n",
        "Но прежде чем мы продолжим, давайте приступим к созданию модели. Мы определим Sequential, как и раньше, добавив в его начале несколько сверточных слоев. \n",
        "Обратите внимание: поскольку здесь у нас задача классификации на два класса, то есть задача *двоичной классификации*, в последнем слое сети мы поставим функцию активации [*sigmoid* активации](https://wikipedia.org/wiki/Sigmoid_function), чтобы на выходе нашей сети был один скаляр от 0 до 1, кодирующим вероятность того, что текущее изображение относится к классу 1 (а не классу 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PixZ2s5QbYQ3"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2), \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(), \n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZKj8392nbgP"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmtkTn06pKxF"
      },
      "source": [
        "\n",
        "Столбец «output shape» показывает, как размер вашего признак-вектора изменяется на каждом последующем слое. Слои свертки немного уменьшают размер признак-вектора из-за паддинга, а каждый слой пулинга уменьшает размеры вдвое."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEkKSpZlvJXA"
      },
      "source": [
        "Далее мы настроим спецификации для обучения модели. Мы будем обучать нашу модель с функцией потерь `binary_crossentropy`, потому что это задача двоичной классификации, и наша последняя активация - `sigmoid`. (Чтобы узнать больше о функциях потерь, см. [Ускоренный курс машинного обучения](https://developers.google.com/machine-learning/crash-course/descending-into-ml/video-lecture).) Мы будем использовать оптимизатор `rmsprop` со скоростью обучения 0,001. Во время обучения нам нужно будет следить за точностью классификации.\n",
        "\n",
        "**Примечание**: В этом случае использование [RMSprop optimization algorithm](https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp) прдпочтительнее, чем [stochastic gradient descent](https://developers.google.com/machine-learning/glossary/#SGD) (SGD), потому что RMSprop автоматизирует настройку скорости обучения. (Дрпугие оптимизаторы, такие как [Adam](https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam) и [Adagrad](https://developers.google.com/machine-learning/glossary/#AdaGrad), также автоматически адаптируют скорость обучения во время обучения и будут здесь хорошо работать)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DHWhFP_uhq3"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn9m9D3UimHM"
      },
      "source": [
        "### Препроцессинг данных\n",
        "\n",
        "Установим генераторы данных, которые будут считывать изображения из наших исходных папок, преобразовывать их в тензоры `float32` и передавать их (вместе с их метками) в нашу сеть. У нас будет один генератор для обучающих изображений и один для тестовых. Наши генераторы будут формировать пакеты из 20 изображений размером 150x150 и их меток (двоичных).\n",
        "\n",
        "Как вы, возможно, уже знаете, данные, которые поступают в нейронные сети, обычно должны быть нормализованы каким-то образом, чтобы сделать их более доступными для обработки в сети. (Необработанные пиксели редко загружаются в сверточные сети.) В нашем случае мы будем предварительно обрабатывать наши изображения, нормализуя значения пикселей, чтобы они находились в диапазоне [0, 1] (изначально все значения находятся в диапазоне [0, 255] ).\n",
        "\n",
        "В Keras это можно сделать с помощью класса `keras.preprocessing.image.ImageDataGenerator` с помощью параметра `rescale`. Этот класс `ImageDataGenerator` позволяет вам создавать экземпляры генераторов аугментированных пакетов изображений (и их меток) через .flow (data, labels) или .flow_from_directory (directory). Эти генераторы затем можно использовать с методами модели Keras, которые принимают генераторы данных в качестве входных данных: `fit`, ʻevaluate_generator` и` pred_generator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClebU9NJg99G"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255.\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# --------------------\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "# --------------------\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))     \n",
        "# --------------------\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "# --------------------\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode  = 'binary',\n",
        "                                                         target_size = (150, 150))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu3Jdwkjwax4"
      },
      "source": [
        "### Тренировка\n",
        "Let's train on all 2,000 images available, for 15 epochs, and validate on all 1,000 test images. (This may take a few minutes to run.)\n",
        "\n",
        "Do note the values per epoch.\n",
        "\n",
        "You'll see 4 values per epoch -- Loss, Accuracy, Validation Loss and Validation Accuracy. \n",
        "\n",
        "Давайте потренируемся на всех 2000 доступных изображениях в течение 15 эпох и проверим на всех 1000 тестовых изображениях. (Это может занять несколько минут.)\n",
        "\n",
        "Обратите внимание на значения в эпохах.\n",
        "\n",
        "Вы увидите 4 значения для каждой эпохи - потеря, точность, потеря тестирования и точность тестирования.\n",
        "\n",
        "Loss и Accuracy - отличные показатели прогресса обучения. Делается предположение относительно классификации обучающих данных, которое затем сравнивается с известным значением метки и вычисляет результат. Точность - это часть правильных догадок. Точность тестирования - это измерение с данными, которые не использовались при обучении. Как и ожидалось, она будет немного ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb1_lgobv81m"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=15,\n",
        "                              validation_steps=50,\n",
        "                              verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5Vulban4ZrD"
      },
      "source": [
        "### Оценка точности и потерь для модели\n",
        "\n",
        "Построим графики точности и потерь обучения/тестирования, собранных во время обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oj0gTIy4k60"
      },
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc      = history.history[     'accuracy' ]\n",
        "val_acc  = history.history[ 'val_accuracy' ]\n",
        "loss     = history.history[    'loss' ]\n",
        "val_loss = history.history['val_loss' ]\n",
        "\n",
        "epochs   = range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  ( epochs,     acc, label='Training')\n",
        "plt.plot  ( epochs, val_acc, label='Validation')\n",
        "plt.title ('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  ( epochs,     loss, label='Training')\n",
        "plt.plot  ( epochs, val_loss, label='Validation')\n",
        "plt.legend()\n",
        "plt.title ('Training and validation loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgmSjUST4qoS"
      },
      "source": [
        "Как видите, здесь **переобучение**: как будто график вышел из формы. Точность обучения (синим цветом) приближается к 100% (!), А точность проверки (оранжевым цветом) остается на уровне 70%. Наши потери при тестировании достигают минимума всего через пять эпох.\n",
        "\n",
        "Поскольку у нас относительно небольшое количество обучающих примеров (2000), переобучение должно быть нашей проблемой номер один. Переобучение происходит, когда модель, видевшая слишком мало примеров, обучается шаблонам, которые не обобщаются на новые данные, то есть когда модель начинает использовать нерелевантные признаки для прогнозирования. Например, если вы, как человек, видите только три изображения людей-лесорубов и три изображения людей-моряков, и среди них единственный человек в кепке - лесоруб, вы можете подумать, что в кепке - признак того, что он лесоруб, а не моряк. Тогда из вас получится довольно паршивый классификатор лесорубов / матросов.\n",
        "\n",
        "\n",
        "Переобучение - центральная проблема в машинном обучении: учитывая, что мы подгоняем параметры нашей модели к заданному набору данных, как мы можем быть уверены, что обобщения, выученные моделью, будут применимы к данным, которых никогда раньше не было? Как нам избежать запоминания вещей, специфичных для обучающих данных?\n",
        "\n",
        "В следующем упражнении мы рассмотрим способы предотвращения переобучения в модели классификации кошек и собак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smI2o8rbNlEr"
      },
      "source": [
        "## Сохранение модели\n",
        "\n",
        "В ячейке ниже сохраните обученную модель как модель Keras.(файл `.h5`).\n",
        "\n",
        "**Подсказка**: Используйте `model.save()`.\n",
        "Если не помните, как - загляните в пример `Linear-to-JavaScript.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8LBu8zgNn-z"
      },
      "source": [
        "# EXERCISE: Save the trained model as a Keras HDF5 file. \n",
        "\n",
        "saved_model_path = \"./my_model.h5\"\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzDtTYpxeAzR"
      },
      "source": [
        "## Запустите конвертер TensorFlow.js в сохраненной модели Keras\n",
        "\n",
        "В ячейке ниже используйте `tensorflowjs_converter`, чтобы преобразовать сохраненную модель Keras в формат JSON.\n",
        "**ПОДСКАЗКА**: Убедитесь, что вы указали формат входной модели как Keras, используя параметр `--input_format`. Не стесняйтесь взглянуть на пример `Linear-to-JavaScript.ipynb` и в документацию [TensorFlow.js converter documentation](https://github.com/tensorflow/tfjs/tree/master/tfjs-converter#step-1-converting-a-tensorflow-savedmodel-tensorflow-hub-module-keras-hdf5-or-tfkeras-savedmodel-to-a-web-friendly-format)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r5jrUuKNe73"
      },
      "source": [
        "# EXERCISE: Use the tensorflow.js converter to convert the saved Keras model into JSON format.\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBCDWtOEQSTj"
      },
      "source": [
        "Если вы все сделали правильно, теперь у вас должен быть файл **JSON** с именем `model.json` и несколько файлов `.bin`, таких как `group1-shard1of10.bin`. Количество файлов .bin будет зависеть от размера вашей модели: чем больше ваша модель, тем больше будет файлов .bin. Файл `model.json` содержит архитектуру вашей модели, а файлы `.bin` будут содержать веса вашей модели."
      ]
    }
  ]
}